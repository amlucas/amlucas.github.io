
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>blog - gnn-local-interactions</title>
  <link rel="stylesheet" href="../css/main.css" />
  <link rel="stylesheet" href="../css/codehilite.css" />
  <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>
<body>

<nav class="top-nav">
  <a href="../index.html">Home</a>
  <a href="../blog.html">Blog</a>
</nav>


<section class="markdown-body">
  <h1>Graph Neural Networks to learn an energy potential</h1>
<p>May 20, 2024</p>
<p>Graph neural networks (GNNs) are an increasingly popular approach to learn from complex data structures that can be represented as graphs.
In computational science we can often represent a physical system by a graph:</p>
<ul>
<li>A computational grid is a set of nodes connected with each other.</li>
<li>Molecular dynamics is essentially a list of particles (nodes) interacting with pairwise forces (edges).</li>
<li>Unstructured grids to represent PDEs.</li>
<li>Triangle mesh surfaces to represent membranes.</li>
</ul>
<div class="image-wrap float-img-right" style="width: 50%;">
  <img src="../images/blog/gnn-local-interactions/dataset.svg" alt="The training data, 500 particles uniformly placed in a square box.">
  <p class="image-caption">The training data, 500 particles uniformly placed in a square box.</p>
</div>

<p>To test this method I generated <script type="math/tex"> N </script> particles in a square 2D domain, with random positions <script type="math/tex">\mathbf{r}_i \sim \mathcal{U}\left([0, L] \times [0, L]\right)</script>, <script type="math/tex">i = 1, 2, \dots, N</script>.
Each particle has an associated feature <script type="math/tex">m_i \sim \mathcal{U}(0.1, 1)</script>.
These are the state of the system.</p>
<p>Now, we define an "energy" associated with each particle, that can be computed from the state of the system:
<script type="math/tex; mode=display">
E_i = \sum\limits_{j \neq i, r_{ij} < r_c} m_i m_j w(r_{ij}),
</script>
where <script type="math/tex">r_c = 1</script> is the cutoff radius, <script type="math/tex">r_{ij}</script> the distance separating particles <script type="math/tex">i</script> and <script type="math/tex">j</script> and <script type="math/tex">w(r)=\max\left(0, 1 - \frac{r}{r_c}\right)</script>.</p>
<p>The training data, 500 particles placed randomly in a square box, is illustrated on the right image.
The color shows the energy.</p>
<p>Let's suppose that we have data about the energy of particles in a given configuration, can we predict the energy of particles in a new situation, without knowing the form of the energy?</p>
<p>The GNN architecture is set as follows:
<script type="math/tex; mode=display">
y_i = \sum\limits_{j: (i,j) \in E} \phi(m_i, m_j, \mathbf{e}_{ij}),
</script>
where <script type="math/tex">y_i</script> is the output at node <script type="math/tex">i</script> and the edge features are the direction between particles and their distance, <script type="math/tex">\mathbf{e}_{ij} = \left(\mathbf{r}_{ij} / r_{ij}, r_{ij}\right)</script>.
The function <script type="math/tex">\phi</script> is a multi layer perceptron.
Note that in this case the direction between particles is not useful, but we assume that we don't know this information.</p>
<p>This is easily implemented using <a href="https://pytorch-geometric.readthedocs.io/en/latest/index.html">pytorch-geometric</a>:</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">EdgeConv</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_channels</span><span class="p">,</span> <span class="n">e_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="s1">&#39;add&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x_channels</span> <span class="o">+</span> <span class="n">e_channels</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
                              <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                              <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_attr</span><span class="o">=</span><span class="n">edge_attr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">message</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_i</span><span class="p">,</span> <span class="n">x_j</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x_i</span><span class="p">,</span> <span class="n">x_j</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_channels</span><span class="p">,</span> <span class="n">e_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">EdgeConv</span><span class="p">(</span><span class="n">x_channels</span><span class="p">,</span> <span class="n">e_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_attr</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">)</span>
</code></pre></div>

<p>We train for 20000 epochs using the Adam optimizer with a learning rate of 0.001.
Here are the results, the model tested on a new random configuration:</p>
<div class="image-wrap float-img-center" style="width: 75%;">
  <img src="../images/blog/gnn-local-interactions/comp_xyE.svg" alt="">

</div>

<div class="image-wrap float-img-center" style="width: 65%;">
  <img src="../images/blog/gnn-local-interactions/comp_E.svg" alt="">

</div>

<p>The prediction of the energy is very close to the ground truth on the test data.</p>
</section>


</body>
</html>
